{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BFPVeyk2iZt",
        "outputId": "a8390e1e-3ce6-41ed-babb-632885830080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Product name to search for: dell leptop\n",
            "amazon scraping status: 503\n",
            "flipkart scraping status: 529\n",
            "+------+-----------------------+-------------+\n",
            "| S.NO | flipkart Product Name | Price (INR) |\n",
            "+------+-----------------------+-------------+\n",
            "+------+-----------------------+-------------+\n",
            "+------+---------------------+-------------+\n",
            "| S.NO | amazon Product Name | Price (INR) |\n",
            "+------+---------------------+-------------+\n",
            "+------+---------------------+-------------+\n"
          ]
        }
      ],
      "source": [
        "import requests as rq\n",
        "import bs4 as bs4\n",
        "import random\n",
        "import prettytable as pt\n",
        "\n",
        "class ProductScraper:\n",
        "    def __init__(self, product_name):\n",
        "        self.product_name = str(product_name).replace(\" \", \"+\")\n",
        "\n",
        "    def amazon_url(self):\n",
        "        return f\"https://www.amazon.in/s?k={self.product_name}\"\n",
        "\n",
        "    def flipkart_url(self):\n",
        "        return f\"https://www.flipkart.com/search?q={self.product_name}\"\n",
        "\n",
        "    def product_urls(self):\n",
        "        return {\"amazon\": self.amazon_url(), \"flipkart\": self.flipkart_url()}\n",
        "\n",
        "\n",
        "class WebScraper:\n",
        "    def __init__(self, product_scraper):\n",
        "        self.custom_headers_list = [\n",
        "            {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/119.0',\n",
        "             \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\"},\n",
        "            {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',\n",
        "             \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\"},\n",
        "            {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.4 Safari/605.1.15',\n",
        "             \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\"},\n",
        "        ]\n",
        "        self.urls = product_scraper.product_urls()\n",
        "        self.htmls = self.get_htmls()\n",
        "\n",
        "    def make_request(self):\n",
        "        stat_codes = {}\n",
        "        resp = {}\n",
        "        for url in self.urls:\n",
        "            req = rq.get(self.urls[url], headers=self.custom_headers_list[random.randint(0, 2)])\n",
        "            resp[url] = req.content\n",
        "            stat_codes[url] = req.status_code\n",
        "        response = {\"status\": stat_codes, \"response\": resp}\n",
        "        return response\n",
        "\n",
        "    def get_htmls(self):\n",
        "        self.htmls = {}\n",
        "        response = self.make_request()[\"response\"]\n",
        "        for pf in response:\n",
        "            html = bs4.BeautifulSoup(response[pf], \"html.parser\")  # Changed to 'html.parser'\n",
        "            self.htmls[pf] = html\n",
        "        return self.htmls\n",
        "\n",
        "    def clean_html_tags(self, obj):\n",
        "        for i in range(len(obj)):\n",
        "            obj[i] = obj[i].string\n",
        "\n",
        "    def get_names(self):\n",
        "        names = {}\n",
        "        for html in self.htmls:\n",
        "            name = []\n",
        "            if html == 'amazon':\n",
        "                name = self.htmls[html].select('div.puisg-col-inner span.a-size-medium.a-color-base.a-text-normal')\n",
        "                name.extend(self.htmls[html].select('div.puisg-col-inner span.a-size-base-plus.a-color-base.a-text-normal'))\n",
        "                self.clean_html_tags(name)\n",
        "                for i in range(len(name)):\n",
        "                    if len(name[i]) > 50:\n",
        "                        name[i] = name[i][:51] + \"...\"\n",
        "                names[html] = name\n",
        "            elif html == 'flipkart':\n",
        "                name = self.htmls[html].find_all('div', {'class': '_4rR01T'})\n",
        "                name.extend(self.htmls[html].find_all('a', {'class': 's1Q9rs'}))\n",
        "                name.extend(self.htmls[html].find_all('a', {'class': 'IRpwTa'}))\n",
        "                self.clean_html_tags(name)\n",
        "                names[html] = name\n",
        "        return names\n",
        "\n",
        "    def get_prices(self):\n",
        "        prices = {}\n",
        "        for html in self.htmls:\n",
        "            price = []\n",
        "            if html == 'amazon':\n",
        "                price = self.htmls[html].select('div.puisg-col-inner span.a-price-whole')\n",
        "                self.clean_html_tags(price)\n",
        "                for i in range(len(price)):\n",
        "                    price[i] = \"â‚¹\" + price[i].text if price[i] else \"PNA\"  # Fixed price extraction\n",
        "                prices[html] = price\n",
        "            elif html == 'flipkart':\n",
        "                price = self.htmls[html].find_all('div', {'class': '_30jeq3'})\n",
        "                self.clean_html_tags(price)\n",
        "                prices[html] = price\n",
        "        return prices\n",
        "\n",
        "    def get_product_info(self):\n",
        "        return {\n",
        "            \"amazon\": {\"name\": self.get_names()[\"amazon\"], \"price\": self.get_prices()[\"amazon\"]},\n",
        "            \"flipkart\": {\"name\": self.get_names()[\"flipkart\"], \"price\": self.get_prices()[\"flipkart\"]}\n",
        "        }\n",
        "\n",
        "\n",
        "class PriceComparison:\n",
        "    @staticmethod\n",
        "    def status_check(web_scraper):\n",
        "        req_val = web_scraper.make_request()[\"status\"]\n",
        "        for val in req_val:\n",
        "            print(f\"{val} scraping status: {req_val[val]}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def print_table(product_info, product_website):\n",
        "        names = product_info[product_website][\"name\"]\n",
        "        prices = product_info[product_website][\"price\"]\n",
        "        table = pt.PrettyTable(align='l')\n",
        "        table.field_names = [\"S.NO\", f\"{product_website} Product Name\", \"Price (INR)\"]\n",
        "        no = 1\n",
        "        for no, (name, price) in enumerate(zip(names, prices), start=1):\n",
        "            if price is not None:\n",
        "                table.add_row([no, name, price])\n",
        "            else:\n",
        "                table.add_row([no, name, \"Price not available\"])\n",
        "        print(table)\n",
        "\n",
        "\n",
        "# Main Execution Block\n",
        "product_name = str(input(\"Enter Product name to search for: \"))\n",
        "product_scraper = ProductScraper(product_name)\n",
        "web_scraper = WebScraper(product_scraper)\n",
        "\n",
        "# Check scraping status\n",
        "PriceComparison.status_check(web_scraper)\n",
        "\n",
        "# Print product price comparison tables\n",
        "PriceComparison.print_table(web_scraper.get_product_info(), \"flipkart\")\n",
        "PriceComparison.print_table(web_scraper.get_product_info(), \"amazon\")\n"
      ]
    }
  ]
}